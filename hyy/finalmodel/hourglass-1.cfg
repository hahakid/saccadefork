[net]
# Testing
#batch=1
#subdivisions=1
# Training
batch=64
subdivisions=8
width=640
height=384
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.001
burn_in=1000
max_batches = 10000
policy=steps
steps=5000,7000
scales=.1,.1

#pre-resize:conv 3 128 7*7 2
#downsample=512*128
[convolutional]
batch_normalize=1
filters=128
size=7
stride=2
pad=3 #pad=(k-1)/2=(7-1)/2=3
activation=relu

#pre-resize:resudual-1  conv 128 256 3*3 2
#downsample=256*64
[convolutional]
batch_normalize=1
filters=128 #256
size=3
stride=2
pad=1
activation=relu

#pre-resize:resudual-2  conv 256 256 3*3 1
[convolutional]
batch_normalize=1
filters=128 #256
size=3
stride=1
pad=1
activation=relu

#pre-resize:resudual-2  shortcut
[shortcut]
from=-2
activation=relu

#hourglass

#hourglass-layer1-up1-resudual 256,256,3,1
[convolutional]
batch_normalize=1
filters=128 #256
size=3
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=128 #256
size=3
stride=1
pad=1
activation=relu

[shortcut]
from=-2
activation=relu

#hourglass-layer1-low1 256,384,3,2
#before up1
[route] 
layers = -4

#downsample=128*32
[convolutional]
batch_normalize=1
filters=192 #384
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=192 #384
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-2
activation=relu

#hourglass-layer1-low2-layer2-up1 384,384,3,1
[convolutional]
batch_normalize=1
filters=192 #384
size=3
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=192 #384
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-2
activation=relu

#hourglass-layer1-low2-layer2-low1 384,384,3,2
[route]
layers=-4

#downsample=64*16
[convolutional]
batch_normalize=1
filters=192 #384
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=192 #384
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-2
activation=relu

#hourglass-layer1-low2-layer2-low2-layer3-up1 384,384,3,1
[convolutional]
batch_normalize=1
filters=192 #384
size=3
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=192 #384
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-2
activation=relu

#hourglass-layer1-low2-layer2-low2-layer3-low1 384,512,3,2
[route]
layers=-4

#downsample=32*8
[convolutional]
batch_normalize=1
filters=256 #512
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256 #512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-2
activation=relu

#hourglass-layer1-low2-layer2-low2-layer3-low2 512,512,3,1
[convolutional]
batch_normalize=1
filters=256 #512
size=3
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256 #512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-2
activation=relu

#hourglass-layer1-low2-layer2-low2-layer3-low3 512,512,3,1
[convolutional]
batch_normalize=1
filters=192 #384
size=3
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=192 #384
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-2
activation=relu

#hourglass-layer1-low2-layer2-low2-layer3-up2
#upsample=64*16
[upsample]
stride=2

#hourglass-layer1-low2-layer2-low2-layer3-merg= up2+up1 (layer2)
[route]
layers = -1, -12

#hourglass-layer1-low2-layer2-low3
[convolutional]
batch_normalize=1
filters=192 #384
size=3
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=192 #384
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-2
activation=relu

#hourglass-layer1-low2-layer2-up2
#upsample=128*32
[upsample]
stride=2

#hourglass-layer1-low2-layer2-merge = up2+up1 (layer2)
[route]
layers = -1, -24

#hourglass-layer1-low3
[convolutional]
batch_normalize=1
filters=128 #256
size=3
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=128 #256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-2
activation=relu

#hourglass-layer1-up2
#upsample=256*64
[upsample]
stride=2

#hourglass-layer1-merge
[route]
layers=-1, -36

###########

[convolutional]
batch_normalize=1
filters=128 #256
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=128 #256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=128 #256
size=3
stride=1
pad=1
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=18
activation=linear

[yolo]
mask = 3,4,5
anchors = 23, 17,  48, 32,  73, 57, 122, 74, 159,144, 216,262
classes=1
num=6
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=0

[route]
layers = -4

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[upsample]
stride=2

[route]
layers = -1, 5

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=18
activation=linear

[yolo]
mask = 0,1,2
anchors = 23, 17,  48, 32,  73, 57, 122, 74, 159,144, 216,262
classes=1
num=6
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=0
