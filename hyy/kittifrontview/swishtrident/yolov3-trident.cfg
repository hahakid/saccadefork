[net]
# Testing
#batch=1
#subdivisions=1
# Training
batch=64
subdivisions=8
width=1024
height=256
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.001
burn_in=1000
max_batches = 20000
policy=steps
steps=10000,15000
scales=.1,.1

[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

# Downsample

[convolutional]
batch_normalize=1
filters=64
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

# Downsample

[convolutional]
batch_normalize=1
filters=128
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

# Downsample

[convolutional]
batch_normalize=1
filters=256
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

# Downsample

[convolutional]
batch_normalize=1
filters=512
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

# Downsample

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

######################

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

#79
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

### TridentNet - large objects - Start
#1-80
[convolutional]
batch_normalize=1
filters=64 #256
size=1
stride=1
pad=1
activation=leaky
#2-81
[convolutional]
dilation=3
batch_normalize=1
filters=64 #256
size=3
stride=1
pad=1
activation=leaky
#3-82
[convolutional]
batch_normalize=1
filters=256 #1024
size=1
stride=1
pad=1
activation=linear
#4-83
[shortcut]
from=-4
activation=leaky
#5-84
[convolutional]
batch_normalize=1
filters=64 #256
size=1
stride=1
pad=1
activation=leaky
#6-85
[convolutional]
dilation=3
batch_normalize=1
filters=64 #256
size=3
stride=1
pad=1
activation=leaky
#7-86
[convolutional]
batch_normalize=1
filters=256 #1024
size=1
stride=1
pad=1
activation=linear
#8-87
[shortcut]
from=-4
activation=leaky
#9-88
[convolutional]
batch_normalize=1
filters=64 #256
size=1
stride=1
pad=1
activation=leaky
#10-89
[convolutional]
dilation=3
batch_normalize=1
filters=64 #256
size=3
stride=1
pad=1
activation=leaky
#11-90
[convolutional]
batch_normalize=1
filters=256 #1024
size=1
stride=1
pad=1
activation=linear
#91
[shortcut]
from=-4
activation=leaky

#92
## Conv 5
[convolutional]
batch_normalize=1
filters=128 #512
size=1
stride=1
pad=1
activation=leaky
#93
[convolutional]
dilation=3
batch_normalize=1
filters=128 #512
size=3
stride=2
pad=1
activation=leaky
#94
[convolutional]
batch_normalize=1
filters=512 #2048
size=1
stride=1
pad=1
activation=linear
#95
[shortcut]
from=-4
activation=leaky
#96
[convolutional]
batch_normalize=1
filters=128 #512
size=1
stride=1
pad=1
activation=leaky
#97
[convolutional]
dilation=3
batch_normalize=1
filters=128 #512
size=3
stride=1
pad=1
activation=leaky
#98
[convolutional]
batch_normalize=1
filters=512 #2048
size=1
stride=1
pad=1
activation=linear

#99
[shortcut]
from=-4
activation=leaky
#100
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

#101
[convolutional]
size=1
stride=1
pad=1
filters=32
activation=linear

#102
[yolo]
mask = 8,9,10,11
anchors = 21, 15,  37, 22,  21, 42,  57, 30,  40, 79,  72, 48, 106, 36, 123, 63,  76,123, 180, 82, 220,121, 316,143
classes=3
num=12
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=0

### TridentNet - large objects - End

### TridentNet - medium objects - Start
#67
[route]
layers = 79
#68
[convolutional]
share_index=80
batch_normalize=1
filters=64 #256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
share_index=81
dilation=2
batch_normalize=1
filters=64 #256
size=3
stride=1
pad=1
activation=leaky

[convolutional]
share_index=82
batch_normalize=1
filters=256 #1024
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-4
activation=leaky

[convolutional]
share_index=84
batch_normalize=1
filters=64 #256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
share_index=85
dilation=2
batch_normalize=1
filters=64 #256
size=3
stride=1
pad=1
activation=leaky

[convolutional]
share_index=86
batch_normalize=1
filters=256 #1024
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-4
activation=leaky

[convolutional]
share_index=88
batch_normalize=1
filters=64 #256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
share_index=89
dilation=2
batch_normalize=1
filters=64 #256
size=3
stride=1
pad=1
activation=leaky

[convolutional]
share_index=90
batch_normalize=1
filters=256 #1024
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-4
activation=leaky


## Conv 5
[convolutional]
share_index=92
batch_normalize=1
filters=128 #512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
share_index=93
dilation=2
batch_normalize=1
filters=128 #512
size=3
stride=2
pad=1
activation=leaky

[convolutional]
share_index=94
batch_normalize=1
filters=512 #2048
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-4
activation=leaky

[convolutional]
share_index=96
batch_normalize=1
filters=128 #512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
share_index=97
dilation=2
batch_normalize=1
filters=128 #512
size=3
stride=1
pad=1
activation=leaky

[convolutional]
share_index=98
batch_normalize=1
filters=512 #2048
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-4
activation=leaky

[convolutional]
batch_normalize=1
size=1
stride=1
pad=1
filters=256 #1024
activation=leaky

[upsample]
stride=2

[route]
layers = -1, 62

[convolutional]
batch_normalize=1
size=1
stride=1
pad=1
filters=256 #1024
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=32
activation=linear

[yolo]
mask = 4,5,6,7
anchors = 23, 16,  20, 42,  42, 23,  56, 38,  87, 30,  40, 79,  97, 53,  76,122, 150, 66, 191, 96, 225,130, 319,141
classes=3
num=12
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=0

### TridentNet - medium objects - End


### TridentNet - small objects - Start

[route]
layers = 79

[convolutional]
share_index=80
batch_normalize=1
filters=64 #256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
share_index=81
dilation=1
batch_normalize=1
filters=64 #256
size=3
stride=1
pad=1
activation=leaky

[convolutional]
share_index=82
batch_normalize=1
filters=256 #1024
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-4
activation=leaky

[convolutional]
share_index=84
batch_normalize=1
filters=64 #256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
share_index=85
dilation=1
batch_normalize=1
filters=64 #256
size=3
stride=1
pad=1
activation=leaky

[convolutional]
share_index=86
batch_normalize=1
filters=256 #1024
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-4
activation=leaky

[convolutional]
share_index=88
batch_normalize=1
filters=64 #256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
share_index=89
dilation=1
batch_normalize=1
filters=64 #256
size=3
stride=1
pad=1
activation=leaky

[convolutional]
share_index=90
batch_normalize=1
filters=256 #1024
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-4
activation=leaky


## Conv 5
[convolutional]
share_index=92
batch_normalize=1
filters=128 #512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
share_index=93
dilation=1
batch_normalize=1
filters=128 #512
size=3
stride=2
pad=1
activation=leaky

[convolutional]
share_index=94
batch_normalize=1
filters=512 #2048
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-4
activation=leaky

[convolutional]
share_index=96
batch_normalize=1
filters=128 #512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
share_index=97
dilation=1
batch_normalize=1
filters=128 #512
size=3
stride=1
pad=1
activation=leaky

[convolutional]
share_index=98
batch_normalize=1
filters=512 #2048
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-4
activation=leaky

[convolutional]
batch_normalize=1
size=1
stride=1
pad=1
filters=128 #512
activation=leaky

[upsample]
stride=4

[route]
layers = -1, 38

[convolutional]
batch_normalize=1
size=1
stride=1
pad=1
filters=128 #512
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=32
activation=linear

[yolo]
mask = 0,1,2,3
anchors = 23, 16,  20, 42,  42, 23,  56, 38,  87, 30,  40, 79,  97, 53,  76,122, 150, 66, 191, 96, 225,130, 319,141
classes=3
num=12
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=0

### TridentNet - small objects - End
